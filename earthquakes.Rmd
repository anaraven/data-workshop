---
title: "Energy of Earthquakes"
author: "Andrés Aravena"
date: "19 May 2015"
output:
  html_document:
    fig_caption: yes
    self_contained: no
    theme: united
---

On March 21st, 2015 the solar equinoxe coincided with a solar eclipse. Even if that day was cloudy on Istanbul the reduction of daylight was evident. A friend of mine asked me if I was concerned with the risks of earthquakes on that particular day. Apparently there is a belief that full moons or eclipses trigger seisms. Given that moon gravity is capable of generating oceanic tides, this is indeed something that worths further research.

Since we are in a data science workshop I asked "what can we do to test this hypothesis?". The standard approach is to gather some data, possibly from public databases, process it with the tools we learned, and test the hypothesis of correlation.

In this first document I will address the seismic data, while the astronomical data will be examined in a following document.

# Gathering data
A quick search with Google point us to the [Centennial Earthquake Catalog](http://earthquake.usgs.gov/data/centennial/) (Engdahl and Villaseñor, 2002) which is a global catalog of locations and magnitudes of instrumentally recorded earthquakes from 1900 to 2008. 

There are several files on this web page:

+ **centennial_README.rtf** - documentation in Rich Text Format
+ **centennial.cat** - catalog in text format
+ **plate15.pdf** - color plate 15 of Engdahl and Villaseñor (2002)
+ **plate16.pdf** - color plate 16 of Engdahl and Villaseñor (2002)

They include nice pictures such as *Plate 15*:

![**Plate 15 from Engdahl and Villaseñor, 2002.** 
Global earthquake locations from 1900 to 1999 taken from the centennial catalog.
Bathymetry/topography are from the database of Smith and Sandwell (1997).
Earthquakes relocated in this study are shown by filled circles and unrelocated earthquakes by filled hexagons.
Symbol fill is color-coded according to focal depth *h*: 
red=shallow events (*h*<70 km); yellow=intermediate (70≤*h*<350 km); and blue=deep (*h*≥350 km). A thick symbol outline is used for events with magnitudes greater or equal than 8.0.](centennial_plate15.png)

The main table is in the file `"centennial_Y2K.CAT.txt"`.
If we read it using `read.table()`, something weird happens.

```{r fake-read, error=TRUE, cache=TRUE}
data <- read.table("centennial_Y2K.CAT")
```

so whitespace is not the good separator. Let's try with *Tab*.

```{r fake-read-2,cache=TRUE}
data <- read.table("centennial_Y2K.CAT", sep="\t")
```

This time it works. The resulting `data.frame` has `r nrow(data)` rows and `r ncol(data)` columns. That does not sound good. Let's take a look at the summary of the table

```{r summary}
summary(data)
```
So, all the data, including whitespace, is in a single column! Maybe is a good time to take a look at the documentation in `centennial_README.rtf`.
It is always a good idea to read the *Readme* files. It says

```
CAT FILE FORMAT

Fortran read statement:

       integer yr,day,hr,greg
       read(1,100) icat,asol,isol,yr,mon,day,hr,min,sec,
     1 glat,glon,dep,greg,ntel,(mag(k),msc(k),mdo(k),k=1,12)
  100  format(a6,a1,a5,i4,2i3,1x,2i3,f6.2,1x,2f8.3,f6.1,2i4,
     1 12(f4.1,1x,a2,1x,a5))
```

Ok. *Fortran* was a language that my dad used in his university days. But is still used in many cientific calculations because:

+ there are many old programs written on fortran that scientist still use
+ many new programs are adaptations of the old ones
+ it is *very* efficient for these tasks
+ it works

The *read statement* should be unerstood as:

+ The variables `yr, day, hr` and `greg` are *integers*.
+ The column names are `icat, asol, isol, yr, mon, day, hr, min, sec,`
`glat, glon, dep, greg, ntel, mag(1), msc(1), mdo(1), mag(2), msc(2), mdo(2),`
`mag(3), msc(3), mdo(3), mag(4), msc(4), mdo(4), mag(5), msc(5), mdo(5),`
`mag(6), msc(6), mdo(6), mag(7), msc(7), mdo(7), mag(8), msc(8), mdo(8),`
`mag(9), msc(9), mdo(9), mag(10), msc(10), mdo(10), mag(11), msc(11), mdo(11),`
`mag(12), msc(12), mdo(12)`. Notice the clever notation of the last 36 columns.
+ The *format* of the columns is `a6, a1, a5, i4, 2i3, 1x, 2i3, f6.2, 1x, 2f8.3, f6.1, 2i4, 12(f4.1, 1x, a2, 1x, a5)`. This is a little cryptic but we will not care too much.

How do we read *Fortran* data in R? Google says that we can use the function `read.fortran`. We are lucky! In fact it is not so unexpected since people uses Fortran and R for data analysis. Some of the internal functions of R are indeed programmed in Fortran.

The *format* is a vector
```{r fmt}
fmt <- c("A6", "A1", "A5", "I4", "2I3", "1X", "2I3", "F6.0", "1X", 
         "2F8.0", "F6.0", "2I4",
         rep(c("F4.0", "1X", "A2", "1X", "A5"),12))
```
Now we can read the data with the command
```{r read, cache=TRUE}
data <- read.fortran("centennial_Y2K.CAT", fmt)
```

Now we have `r nrow(data)` rows and `r ncol(data)` columns. That sounds good.
Let us give names to the columns cutting and pasting from the documentation

```{r colnames}
colnames(data) <- c("icat", "asol", "isol", "yr", "mon", "day", "hr", "min", "sec",
                    "glat", "glon", "dep", "greg", "ntel", "mag.1", "msc.1", "mdo.1", 
                    "mag.2", "msc.2", "mdo.2", "mag.3", "msc.3", "mdo.3", 
                    "mag.4", "msc.4", "mdo.4", "mag.5", "msc.5", "mdo.5", 
                    "mag.6", "msc.6", "mdo.6", "mag.7", "msc.7", "mdo.7", 
                    "mag.8", "msc.8", "mdo.8", "mag.9", "msc.9", "mdo.9", 
                    "mag.10", "msc.10", "mdo.10", "mag.11", "msc.11", "mdo.11", 
                    "mag.12", "msc.12", "mdo.12")
```
Let's take a look at the most relevant columns
```{r summary2}
summary(data[,4:15])
```
So *year* goes from `r min(data$yr)` to `r max(data$yr)`, which is reasonable. 

# Energy
```{r energy}
energy <- exp(3*log(10)*(data$mag.1 + 2.9)/2)
plot(sort(energy)/sum(energy))
```

# Map
The column *longitude* takes values between `r min(data$glon)` to `r max(data$glon)`, but in this case we would like to have them in the range 0 to 360 degrees. We define then *latitude* and *longitude* as
```{r latlon}
lat <- data$glat
long <- data$glon + ifelse(data$glon<0, 360, 0)
```
Following the definitions in *Plate 15* we consider that *big earthquakes* are those with magnitude over 8.0
```{r big}
big.seism <- data$mag.1 > 8.0
```
and we classify them in three ranges of depth using the `cut` function. Use `help(cut)` to understand this function
```{r dep.def}
depth.class <- cut( data$dep, c(-Inf, 70, 350, Inf) )
depth.color <- c("red","yellow","blue")[depth.class]
```

```{r drawmap, fig.height=5, fig.width=10}
#' If necesary install these packages using `install.packages(c("maps", "maptools", "mapdata"))`
library(maps)
library(mapdata)

map("world2Hires")
dot.size <- 0.1 + 2*energy/max(energy)
points(long, lat, pch=21,
       cex = dot.size, 
       col = ifelse(big.seism, "black", depth.color),
       bg  = depth.color)
```

# References

http://earthquake.usgs.gov/learn/topics/measure.php

https://www.e-education.psu.edu/earth520/content/l7_p4.html

http://en.wikipedia.org/wiki/Flinn%E2%80%93Engdahl_regions

http://www.earthquakes.bgs.ac.uk/research/earthquakeSunMoon.html

http://articles.adsabs.harvard.edu//full/1914JRASC...8..273K/0000275.000.html

http://robinlovelace.net/r/2014/01/30/spatial-data-with-R-tutorial.html 

http://stackoverflow.com/questions/1298100/creating-a-movie-from-a-series-of-plots-in-r


Engdahl, E.R., and A. Villaseñor, Global Seismicity: 1900–1999, in W.H.K. Lee, H. Kanamori, P.C. Jennings, and C. Kisslinger (editors), International Handbook of Earthquake and Engineering Seismology, Part A, Chapter 41, pp. 665–690, Academic Press, 2002.

Engdahl, E.R., R. van der Hilst, and R. Buland, Global teleseismic earthquake relocation with improved travel times and procedures for depth determination, Bull. Seism. Soc. Am. 88, 722–743, 1998.
